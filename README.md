# yoloDojang

yolo11n 모델을 이용하여 노트북 웹캠을 통해 실시간으로 간식을 탐지하는 프로젝트

간식 클래스
: ['jeli', 'pota', 'jt', 'br', 'mon']

1. 첫번째 학습
    노트북으로 학습된 걸 테스트 해봤을 때 mon의 뒷모습을 br로 판단하는 오류가 있었음
    또 카메라와 대상의 거리가 멀어질 때 jeli와 jt를 혼동하는 경우가 있었음

2. 두번째 학습
    mon과 br을 겹쳐 놓아도 잘 학습이 되었음. 먼 거리에서도 jeli와 jt 구분이 잘 됨
    간식이 책상 위가 아닌 웹캠 정면에서는 잘 인식하지 못해서 웹캠 정면 데이터를 추가 하려함

3. 세번째 학습
    책상이 아닌 웹캠 정면으로 해도 잘 나왔음, 제티가 가로가 아닌 세로로 있을 때, 좀 멀리 있을 때 인식을 잘 못했음
    ---> 직접 찍어서 보강해도 되겠지만 데이터 증강에서 회전 각도를 범위와 회전 확률을 좀 더 늘렸음
    (45도 --> 90도), (0.3퍼 --> 0.5퍼)
    멀리 있는 과자도 인식이 잘 안됐어서 scale 조정 albemtation을 추가했음
    그리고 과자끼리 뭉쳐있을때 맨 뒤에 가려진 과자가 인식이 잘 안됐음

4. 4번째 학습
    학습 시 earlystopping이 발생함. 웹캠으로 3번째 학습 결과랑 비교해보니 인식률도 떨어짐.
    회전된 train 데이터를 보니 라벨이 과자보다 작게 쳐지거나 과자보다 훨씬 크게 쳐졌음.
    다시 45도로 바꿈

5. 5번째 학습
    웹캠 정면에 있을때는 잘 학습했지만 웹캠의 가장자리로 가고, 캠과의 거리를 멀리 두었을 때 다양한 물체를 대부분 젤리로 인식했음 그래서 가장자리에 있는 거리가 좀 먼 데이터를 추가하려 함
    